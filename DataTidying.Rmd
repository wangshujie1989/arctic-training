---
title: "DataTidying"
author: "ShujieWang"
date: "January 16, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=F, message=F}
library (dplyr)  
library (tidyr)  

```


# Data cleaning

+read in data file
```{r}

##directly retrieve the data from the http, right click the download button and copy the address

catch <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1", method='libcurl'), stringsAsFactors = FALSE)    

head (catch)  


  

```


+Remove marginal sum and notes column
+Remove from wide to long format

```{r}

# use pipe (%>%, ctrl+shift+m) operator to pass the function values other functions without defining new variables to store the intermediate results


# catch_long <- catch %>% 
#   select (Region, Year, Chinook, Sockeye, Coho, Pink, Chum)  

catch_long <- catch %>% 
  select(-All, -notesRegCode) %>% 
  gather (key="species", value="catch", -Year, -Region)

head (catch_long) 


```

+Find the bad values

```{r, eval=F,echo=F}
test_catch <- as.integer(catch_long$catch)

i <- which(is.na(test_catch)==T)

catch_long[i,]


```


+Rename the column 
+erronenus value due to OCR issue, chang i to 1

```{r}
catch_clean <- catch_long %>% 
  rename(catch_thousands = catch)  %>% 
  mutate(catch_thousands= ifelse(catch_thousands=="I","1",catch_thousands)) %>% 
  mutate(catch_thousands=as.integer(catch_thousands)) %>% 
  mutate(catch=catch_thousands*1000)

head(catch_clean)  


```



# Split, apply, combine

+calculate the total catch by region

```{r}

catch_total <- catch_clean %>% 
  group_by(Region, Year) %>% 
  summarise(catch_region=sum(catch), n_obs=n())

head(catch_total)  

```
+filter for chinook
```{r}
catch_chinook <-catch_clean %>% 
  filter(species=="Chinook"|Region=="SSE") %>% 
  arrange(-Year) # sort in descending order




head(catch_chinook) 

```


# Join  

+read in the region_df data

```{r}
region_defs <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.303.1", method = "libcurl"),
                        stringsAsFactors = FALSE)

head(region_defs)  


```
```{r}
region_clean <- region_defs %>% 
  select(code,mgmtArea) %>% 
  rename(Region=code)

head(region_clean)
```
```{r}

catch_join<- left_join(catch_clean,region_clean) #by=c("Region"="code")) 


head(catch_join)
```

# Spread

+make a wide dataframe using spread

```{r}
catch_wide<- catch_clean %>% 
  filter (Year>1990) %>% 
  select(-catch_thousands) %>% 
  spread(key=Year, value=catch)

head(catch_wide)
```

# separate and unite functions

+ YYYY-MM-DD
```{r}
dates_df <- data.frame(date = c("5/24/1930",
                                "5/25/1930",
                                "5/26/1930",
                                "5/27/1930",
                                "5/28/1930"),
                       stringsAsFactors = FALSE)


dates_sep<- dates_df %>% 
  separate(col=date,into = c("month","day","year"),sep="/",remove=F)  

dates_unite<-dates_sep %>% 
  unite(date_iso,year,month,day,sep = "-")



head(dates_sep)
head(dates_unite)

```

